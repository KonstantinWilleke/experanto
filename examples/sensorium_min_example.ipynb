{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86ed3fd1",
   "metadata": {},
   "source": [
    "## Make dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f382d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/turishcheva/anaconda3/envs/sensorium/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/srv/user/turishcheva/experanto_video_dev/experanto/')\n",
    "from experanto.data import Mouse2pVideoDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5138e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'dynamic29712-5-9-Video-full' # mouse\n",
    "path_pre = # path to the folder with mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39700c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = f'{path_pre}{m}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01163b09",
   "metadata": {},
   "source": [
    "**Important**\n",
    "\n",
    "* If the `stim_duration` is below 65 -> change skip parameter here (to 20, for default sensorium configularion)\n",
    "https://github.com/ecker-lab/sensorium_2023/blob/main/sensorium/utility/scores.py#L10\n",
    "* Also note that original sensorium was released in 36 x 64 resolution, 144 x 256 might require more GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a884e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Mouse2pVideoDataset(root_folder=root_folder,\n",
    "        tier='train',\n",
    "        stim_duration=30,\n",
    "        sampling_rate=20,\n",
    "        subsample=True,\n",
    "        cut=True,\n",
    "        add_channel=True,\n",
    "        channel_pos=0,\n",
    "        rescale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fafa26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Mouse2pVideoDataset(\n",
    "    root_folder,\n",
    "    tier='oracle',\n",
    "        stim_duration=30,\n",
    "        sampling_rate=20,\n",
    "        subsample=False, # this would start taking chunks from the begining always\n",
    "        cut=True,\n",
    "        add_channel=True,\n",
    "        channel_pos=0,\n",
    "        rescale=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13fc152d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "data_loaders = OrderedDict()\n",
    "\n",
    "data_loaders['train'] = OrderedDict()\n",
    "data_loaders['oracle'] = OrderedDict()\n",
    "data_loaders['train'][m] =  DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "data_loaders['oracle'][m] = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9696479b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('train',\n",
       "              OrderedDict([('dynamic29712-5-9-Video-full',\n",
       "                            <torch.utils.data.dataloader.DataLoader at 0x7f3fb42f6a60>)])),\n",
       "             ('oracle',\n",
       "              OrderedDict([('dynamic29712-5-9-Video-full',\n",
       "                            <torch.utils.data.dataloader.DataLoader at 0x7f3fb42f6a00>)]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f7630ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/user/turishcheva/experanto_video_dev/experanto/experanto/interpolators.py:211: UserWarning: Image size changes aspect ratio.\n",
      "  warnings.warn(\"Image size changes aspect ratio.\")\n"
     ]
    }
   ],
   "source": [
    "it =next(iter(data_loaders['train'][m]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e6a3482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7939, 30])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it.responses.shape\n",
    "# torch.Size([batch, neurons, times])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "701976d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 30, 144, 256])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it.screen.shape\n",
    "# original dataloader was orch.Size([batch, channels, times, h, w])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71515247",
   "metadata": {},
   "source": [
    "## Make and test forward pass for sensorium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b8d71d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "import sys\n",
    "sys.path.append('/srv/user/turishcheva/sensorium_replicate/sensorium_2023/')\n",
    "sys.path.append('/srv/user/turishcheva/sensorium_replicate/neuralpredictors/')\n",
    "import torch\n",
    "from nnfabrik.utility.nn_helpers import set_random_seed\n",
    "set_random_seed(seed)\n",
    "\n",
    "from sensorium.datasets.mouse_video_loaders import mouse_video_loader\n",
    "from sensorium.utility.scores import get_correlations\n",
    "from nnfabrik.builder import get_trainer\n",
    "from sensorium.models.make_model import make_video_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "872f2031",
   "metadata": {},
   "outputs": [],
   "source": [
    "factorised_3D_core_dict = dict(\n",
    "    input_channels=1, # increase if behaviour is used\n",
    "    hidden_channels=[32, 64, 128],\n",
    "    spatial_input_kernel=(11,11),\n",
    "    temporal_input_kernel=11,\n",
    "    spatial_hidden_kernel=(5,5),\n",
    "    temporal_hidden_kernel=5,\n",
    "    stride=1,\n",
    "    layers=3,\n",
    "    gamma_input_spatial=10,\n",
    "    gamma_input_temporal=0.01, \n",
    "    bias=True, \n",
    "    hidden_nonlinearities='elu', \n",
    "    x_shift=0, \n",
    "    y_shift=0,\n",
    "    batch_norm=True, \n",
    "    laplace_padding=None,\n",
    "    input_regularizer='LaplaceL2norm',\n",
    "    padding=False,\n",
    "    final_nonlin=True,\n",
    "    momentum=0.7\n",
    ")\n",
    "\n",
    "\n",
    "shifter_dict=None\n",
    "\n",
    "\n",
    "readout_dict = dict(\n",
    "    bias=True,\n",
    "    init_mu_range=0.2,\n",
    "    init_sigma=1.0,\n",
    "    gamma_readout=0.0,\n",
    "    gauss_type='full',\n",
    "    grid_mean_predictor=None,\n",
    "#     grid_mean_predictor={\n",
    "#         'type': 'cortex',\n",
    "#         'input_dimensions': 2,\n",
    "#         'hidden_layers': 1,\n",
    "#         'hidden_features': 30,\n",
    "#         'final_tanh': True\n",
    "#     },\n",
    "    share_features=False,\n",
    "    share_grid=False,\n",
    "    shared_match_ids=None,\n",
    "    gamma_grid_dispersion=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88bd645d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/user/turishcheva/experanto_video_dev/experanto/experanto/interpolators.py:211: UserWarning: Image size changes aspect ratio.\n",
      "  warnings.warn(\"Image size changes aspect ratio.\")\n",
      "/srv/user/turishcheva/sensorium_replicate/neuralpredictors/neuralpredictors/layers/cores/base.py:82: UserWarning: The batch_norm is applied to all layers\n",
      "  warnings.warn(f\"The {attr} is applied to all layers\", UserWarning)\n",
      "/srv/user/turishcheva/sensorium_replicate/neuralpredictors/neuralpredictors/layers/cores/base.py:82: UserWarning: The bias is applied to all layers\n",
      "  warnings.warn(f\"The {attr} is applied to all layers\", UserWarning)\n",
      "/srv/user/turishcheva/sensorium_replicate/neuralpredictors/neuralpredictors/layers/cores/base.py:82: UserWarning: The batch_norm_scale is applied to all layers\n",
      "  warnings.warn(f\"The {attr} is applied to all layers\", UserWarning)\n",
      "/srv/user/turishcheva/sensorium_replicate/neuralpredictors/neuralpredictors/layers/readouts/base.py:74: UserWarning: Use of 'gamma_readout' is deprecated. Use 'feature_reg_weight' instead. If 'feature_reg_weight' is defined, 'gamma_readout' is ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "factorised_3d_model = make_video_model(\n",
    "    data_loaders,\n",
    "    seed,\n",
    "    core_dict=factorised_3D_core_dict,\n",
    "    core_type='3D_factorised',\n",
    "    readout_dict=readout_dict.copy(),\n",
    "    readout_type='gaussian',               \n",
    "    use_gru=False,\n",
    "    gru_dict=None,\n",
    "    use_shifter=False,\n",
    "    shifter_dict=shifter_dict,\n",
    "    shifter_type='MLP',\n",
    "    deeplake_ds=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98beb6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoFiringRateEncoder(\n",
       "  (core): Factorized3dCore(\n",
       "    (_input_weight_regularizer): LaplaceL2norm(\n",
       "      (laplace): Laplace()\n",
       "    )\n",
       "    (temporal_regularizer): DepthLaplaceL21d(\n",
       "      (laplace): Laplace1d()\n",
       "    )\n",
       "    (features): Sequential(\n",
       "      (layer0): Sequential(\n",
       "        (conv_spatial): Conv3d(1, 32, kernel_size=(1, 11, 11), stride=(1, 1, 1))\n",
       "        (conv_temporal): Conv3d(32, 32, kernel_size=(11, 1, 1), stride=(1, 1, 1))\n",
       "        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True)\n",
       "        (nonlin): ELU(alpha=1.0)\n",
       "      )\n",
       "      (layer1): Sequential(\n",
       "        (conv_spatial_1): Conv3d(32, 64, kernel_size=(1, 5, 5), stride=(1, 1, 1))\n",
       "        (conv_temporal_1): Conv3d(64, 64, kernel_size=(5, 1, 1), stride=(1, 1, 1))\n",
       "        (norm): BatchNorm3d(64, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True)\n",
       "        (nonlin): ELU(alpha=1.0)\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (conv_spatial_2): Conv3d(64, 128, kernel_size=(1, 5, 5), stride=(1, 1, 1))\n",
       "        (conv_temporal_2): Conv3d(128, 128, kernel_size=(5, 1, 1), stride=(1, 1, 1))\n",
       "        (norm): BatchNorm3d(128, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True)\n",
       "        (nonlin): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "  ) [Factorized3dCore regularizers: gamma_input_spatial = 10|gamma_input_temporal = 0.01]\n",
       "  \n",
       "  (readout): MultipleFullGaussian2d(\n",
       "    (dynamic29712-5-9-Video-full): full FullGaussian2d (128 x 126 x 238 -> 7939) with bias\n",
       "  )\n",
       "  (nonlinearity_fn): ELU(alpha=1.0)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorised_3d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa0cede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:6'\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7163951",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_fn = \"sensorium.training.video_training_loop.standard_trainer\"\n",
    "\n",
    "trainer_config = {\n",
    "    'dataloaders' : data_loaders,\n",
    "    'seed' : 111,\n",
    "    'use_wandb' : False,\n",
    "    'verbose': True,\n",
    "    'lr_decay_steps': 4,\n",
    "    'lr_init': 0.005,\n",
    "    'device' : device,\n",
    "    'detach_core' : False,\n",
    "    \n",
    "    # todo - put this to True if you are using deeplake\n",
    "    # first connections to deeplake may take up for 10 mins\n",
    "    'deeplake_ds' : False,\n",
    "    'checkpoint_save_path': './loc/'\n",
    "                 }\n",
    "\n",
    "trainer = get_trainer(trainer_fn=trainer_fn, \n",
    "                 trainer_config=trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27ae86b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optim_step_count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:36<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 89, Train loss -3303629.555260817, Validation loss -1465832.0479486731\n",
      "EPOCH=1  validation_correlation=0.005241501607030255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:35<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 89, Train loss -1566508.2490987657, Validation loss -754750.5198838328\n",
      "EPOCH=2  validation_correlation=0.012891900318500956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [00:36<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 89, Train loss -8935561.672075795, Validation loss -3730460.4403645247\n",
      "EPOCH=3  validation_correlation=0.020821546704323377\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m validation_score, trainer_output, state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactorised_3d_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/user/turishcheva/sensorium_replicate/sensorium_2023/sensorium/training/video_training_loop.py:180\u001b[0m, in \u001b[0;36mstandard_trainer\u001b[0;34m(model, dataloaders, seed, avg_loss, scale_loss, loss_function, stop_function, loss_accum_batch_n, device, verbose, interval, patience, epoch, lr_init, max_iter, maximize, tolerance, restore_best, lr_decay_steps, lr_decay_factor, min_lr, cb, detach_core, use_wandb, wandb_project, wandb_entity, wandb_name, wandb_model_config, wandb_dataset_config, print_step, save_checkpoints, checkpoint_save_path, chpt_save_step, deeplake_ds, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m batch_no_tot \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# train over epochs\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch, val_obj \u001b[38;5;129;01min\u001b[39;00m early_stopping(\n\u001b[1;32m    181\u001b[0m     model,\n\u001b[1;32m    182\u001b[0m     stop_closure,\n\u001b[1;32m    183\u001b[0m     interval\u001b[38;5;241m=\u001b[39minterval,\n\u001b[1;32m    184\u001b[0m     patience\u001b[38;5;241m=\u001b[39mpatience,\n\u001b[1;32m    185\u001b[0m     start\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m    186\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39mmax_iter,\n\u001b[1;32m    187\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    188\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39mtolerance,\n\u001b[1;32m    189\u001b[0m     restore_best\u001b[38;5;241m=\u001b[39mrestore_best,\n\u001b[1;32m    190\u001b[0m     scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[1;32m    191\u001b[0m     lr_decay_steps\u001b[38;5;241m=\u001b[39mlr_decay_steps,\n\u001b[1;32m    192\u001b[0m ):\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# executes callback function if passed in keyword args\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m         cb()\n",
      "File \u001b[0;32m/srv/user/turishcheva/sensorium_replicate/neuralpredictors/neuralpredictors/training/early_stopping.py:175\u001b[0m, in \u001b[0;36mearly_stopping\u001b[0;34m(model, objective, interval, patience, start, max_iter, maximize, tolerance, switch_mode, restore_best, tracker, scheduler, lr_decay_steps, number_warmup_epochs)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m epoch, current_objective\n\u001b[0;32m--> 175\u001b[0m current_objective \u001b[38;5;241m=\u001b[39m \u001b[43m_objective\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# if a scheduler is defined, a .step with or without the current objective is all that is needed to reduce the LR\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/srv/user/turishcheva/sensorium_replicate/neuralpredictors/neuralpredictors/training/early_stopping.py:105\u001b[0m, in \u001b[0;36mearly_stopping.<locals>._objective\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m switch_mode:\n\u001b[1;32m    104\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 105\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m switch_mode:\n\u001b[1;32m    107\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(training_status)\n",
      "File \u001b[0;32m/srv/user/turishcheva/sensorium_replicate/sensorium_2023/sensorium/utility/scores.py:80\u001b[0m, in \u001b[0;36mget_correlations\u001b[0;34m(model, dataloaders, tier, device, as_dict, per_neuron, deeplake_ds, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m dl \u001b[38;5;241m=\u001b[39m dataloaders[tier] \u001b[38;5;28;01mif\u001b[39;00m tier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dataloaders\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m dl\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 80\u001b[0m     target, output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_predictions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeeplake_ds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeeplake_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     target \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(target, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     88\u001b[0m     output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(output, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m/srv/user/turishcheva/sensorium_replicate/sensorium_2023/sensorium/utility/scores.py:20\u001b[0m, in \u001b[0;36mmodel_predictions\u001b[0;34m(model, dataloader, data_key, device, skip, deeplake_ds)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03mcomputes model predictions for a given dataloader and a model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    target: ground truth, i.e. neuronal firing rates of the neurons\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    output: responses as predicted by the network\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m target, output \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     22\u001b[0m     batch_kwargs \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39m_asdict() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m batch\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deeplake_ds:\n",
      "File \u001b[0;32m~/anaconda3/envs/sensorium/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/sensorium/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/sensorium/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/sensorium/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/srv/user/turishcheva/experanto_video_dev/experanto/experanto/data.py:179\u001b[0m, in \u001b[0;36mMouse2pVideoDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m         times \u001b[38;5;241m=\u001b[39m times[: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstim_duration]\n\u001b[0;32m--> 179\u001b[0m data, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_experiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_channel \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscreen\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m    182\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscreen\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscreen\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_pos)\n",
      "File \u001b[0;32m/srv/user/turishcheva/experanto_video_dev/experanto/experanto/experiment.py:49\u001b[0m, in \u001b[0;36mExperiment.interpolate\u001b[0;34m(self, times, device)\u001b[0m\n\u001b[1;32m     47\u001b[0m     valid \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d, interp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 49\u001b[0m         values[d], valid[d] \u001b[38;5;241m=\u001b[39m \u001b[43minterp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown device \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(device)\n",
      "File \u001b[0;32m/srv/user/turishcheva/experanto_video_dev/experanto/experanto/interpolators.py:190\u001b[0m, in \u001b[0;36mScreenInterpolator.interpolate\u001b[0;34m(self, times)\u001b[0m\n\u001b[1;32m    188\u001b[0m out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros([\u001b[38;5;28mlen\u001b[39m(valid_times)] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image_size))\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m u_idx \u001b[38;5;129;01min\u001b[39;00m unique_file_idx:\n\u001b[0;32m--> 190\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrials\u001b[49m\u001b[43m[\u001b[49m\u001b[43mu_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    192\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(data, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/srv/user/turishcheva/experanto_video_dev/experanto/experanto/interpolators.py:245\u001b[0m, in \u001b[0;36mScreenTrial.get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_data\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39marray:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_file_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sensorium/lib/python3.9/site-packages/numpy/lib/npyio.py:456\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    454\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/anaconda3/envs/sensorium/lib/python3.9/site-packages/numpy/lib/format.py:809\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    808\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    811\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    822\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "validation_score, trainer_output, state_dict = trainer(factorised_3d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478e442",
   "metadata": {},
   "source": [
    "## [Optional] Script to match tiers for new five sensorium mice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f1344b",
   "metadata": {},
   "source": [
    "This works only for [these](https://gin.g-node.org/pollytur/sensorium_2023_dataset) five later released mice.  \n",
    "For [these](https://gin.g-node.org/pollytur/sensorium_2023_data/src/798ba8ad041d8f0f0ce879af396d52c7238c2730) the `trial_idx.npy` file was not released, I am working on this matching and will update it when available\n",
    "\n",
    "Current dataloader will not be able to handle the natural images partition of sensorium, but this was an OOD partition (live and final tests), so this should be fine so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82019ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288365da",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ## mouse name in the older data format (like from gin-g-node)\n",
    "meta_prepre = ## path to the older data format\n",
    "\n",
    "path =f'{meta_prepre}{m}/meta/trials/trial_idx.npy'\n",
    "tiers_old = np.load(f'{meta_prepre}{m}/meta/trials/tiers.npy')\n",
    "trial_idxs_old = np.load(f'{meta_prepre}{m}/meta/trials/trial_idx.npy')\n",
    "\n",
    "\n",
    "tiers_before = []\n",
    "tiers_after = []\n",
    "\n",
    "yaml_prepre = ## path to the new export folder\n",
    "yaml_pre_path = f'{yaml_prepre}{m.split(\"-Video-\")[0]}-Video-full/screen/meta/'\n",
    "\n",
    "for file in tqdm(os.listdir(yaml_pre_path)):\n",
    "    with open(f'{yaml_pre_path}{file}', 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    if data['modality'] != 'blank':\n",
    "        idx = np.where(trial_idxs_old == str(data['trial_idx']))[0]\n",
    "        assert len(idx) <= 1, f'duplicated trial_idxs, {data[\"trial_idx\"]}'\n",
    "        tiers_before.append(data['tier'])\n",
    "        if len(idx) == 0:\n",
    "            print(data[\"trial_idx\"])\n",
    "            data['tier'] = 'none'\n",
    "        else:\n",
    "            data['tier'] = str(tiers_old[idx[0]])\n",
    "        tiers_after.append(data['tier'])\n",
    "        with open(f'{yaml_pre_path}{file}', \"w\") as outfile:\n",
    "            yaml.safe_dump(data, outfile)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
