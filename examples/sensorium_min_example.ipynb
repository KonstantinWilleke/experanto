{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9d831be",
   "metadata": {},
   "source": [
    "## Make dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "412aa32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/turishcheva/anaconda3/envs/sensorium/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/srv/user/turishcheva/experanto_video_dev/experanto/')\n",
    "from experanto.data import Mouse2pVideoDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c57b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5c451a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'dynamic29712-5-9-Video-full' # mouse\n",
    "path_pre = '/usr/users/agecker/datasets/funct_foundational_data/new_export_for_esperanto_dev/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d7fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = f'{path_pre}{m}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e0bc39",
   "metadata": {},
   "source": [
    "**Important**\n",
    "\n",
    "* If the `stim_duration` is below 65 -> change skip parameter here (to 20, for default sensorium configularion)\n",
    "https://github.com/ecker-lab/sensorium_2023/blob/main/sensorium/utility/scores.py#L10\n",
    "* Also note that original sensorium was released in 36 x 64 resolution, 144 x 256 might require more GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03e1c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Mouse2pVideoDataset(root_folder=root_folder,\n",
    "        tier='train',\n",
    "        stim_duration=30,\n",
    "        sampling_rate=30,\n",
    "        subsample=True,\n",
    "        cut=True,\n",
    "        add_channel=True,\n",
    "        channel_pos=0,\n",
    "        interp_config = {\n",
    "            'screen' : {'rescale': True},\n",
    "            'responses' : {'keep_nans' : False, \n",
    "                           'interpolation_mode' : 'linear', \n",
    "                           'interp_window' : 5},\n",
    "            'eye_tracker' : {'keep_nans' : False, \n",
    "                           'interpolation_mode' : 'linear', \n",
    "                           'interp_window' : 5},\n",
    "            'treadmill' : {'keep_nans' : False, \n",
    "                           'interpolation_mode' : 'linear', \n",
    "                           'interp_window' : 5},\n",
    "            }\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2afb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Mouse2pVideoDataset(\n",
    "    root_folder,\n",
    "    tier='oracle',\n",
    "        stim_duration=30,\n",
    "        sampling_rate=30,\n",
    "        subsample=False, # this would start taking chunks from the begining always\n",
    "        cut=True,\n",
    "        add_channel=True,\n",
    "        channel_pos=0,\n",
    "        interp_config = {\n",
    "            'screen' : {'rescale': True},\n",
    "            'responses' : {'keep_nans' : False, \n",
    "                           'interpolation_mode' : 'linear', \n",
    "                           'interp_window' : 5},\n",
    "            'eye_tracker' : {'keep_nans' : False, \n",
    "                           'interpolation_mode' : 'linear', \n",
    "                           'interp_window' : 5},\n",
    "            'treadmill' : {'keep_nans' : False, \n",
    "                           'interpolation_mode' : 'linear', \n",
    "                           'interp_window' : 5},\n",
    "            }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "455b0c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "data_loaders = OrderedDict()\n",
    "\n",
    "data_loaders['train'] = OrderedDict()\n",
    "data_loaders['oracle'] = OrderedDict()\n",
    "data_loaders['train'][m] =  DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "data_loaders['oracle'][m] = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd832af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('train',\n",
       "              OrderedDict([('dynamic29712-5-9-Video-full',\n",
       "                            <torch.utils.data.dataloader.DataLoader at 0x7f986340d730>)])),\n",
       "             ('oracle',\n",
       "              OrderedDict([('dynamic29712-5-9-Video-full',\n",
       "                            <torch.utils.data.dataloader.DataLoader at 0x7f986340d4f0>)]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b18e133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/user/turishcheva/experanto_video_dev/experanto/experanto/interpolators.py:291: UserWarning: Image size changes aspect ratio.\n",
      "  warnings.warn(\"Image size changes aspect ratio.\")\n"
     ]
    }
   ],
   "source": [
    "it =next(iter(data_loaders['train'][m]))\n",
    "# time is always first dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbb05cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44ad42b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 30, 144, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it.screen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d0b6bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7939, 30])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it.responses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9289f190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 30, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it.eye_tracker.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c5ccceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 30])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it.treadmill.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36df1b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9863c6efd0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(it.responses[0, 0], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1186443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1357,  -467,   300],\n",
       "       [-1369,  -478,   300],\n",
       "       [-1304,  -480,   300],\n",
       "       ...,\n",
       "       [ -887,  -321,   225],\n",
       "       [-1039,   118,   225],\n",
       "       [-1249,  -321,   225]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.neurons.cell_motor_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52c6e31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset._experiment.devices['treadmill'].interp_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c493c9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'linear'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset._experiment.devices['treadmill'].interpolation_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e64a61ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset._experiment.devices['treadmill'].keep_nans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041c8721",
   "metadata": {},
   "source": [
    "## Make and test forward pass for sensorium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70c2c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "import sys\n",
    "sys.path.append('/srv/user/turishcheva/sensorium_replicate/sensorium_2023/')\n",
    "sys.path.append('/srv/user/turishcheva/sensorium_replicate/neuralpredictors/')\n",
    "import torch\n",
    "from nnfabrik.utility.nn_helpers import set_random_seed\n",
    "set_random_seed(seed)\n",
    "\n",
    "from sensorium.datasets.mouse_video_loaders import mouse_video_loader\n",
    "from sensorium.utility.scores import get_correlations\n",
    "from nnfabrik.builder import get_trainer\n",
    "from sensorium.models.make_model import make_video_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78705901",
   "metadata": {},
   "outputs": [],
   "source": [
    "factorised_3D_core_dict = dict(\n",
    "    input_channels=1, # increase if behaviour is used\n",
    "    hidden_channels=[32, 64, 128],\n",
    "    spatial_input_kernel=(11,11),\n",
    "    temporal_input_kernel=11,\n",
    "    spatial_hidden_kernel=(5,5),\n",
    "    temporal_hidden_kernel=5,\n",
    "    stride=1,\n",
    "    layers=3,\n",
    "    gamma_input_spatial=10,\n",
    "    gamma_input_temporal=0.01, \n",
    "    bias=True, \n",
    "    hidden_nonlinearities='elu', \n",
    "    x_shift=0, \n",
    "    y_shift=0,\n",
    "    batch_norm=True, \n",
    "    laplace_padding=None,\n",
    "    input_regularizer='LaplaceL2norm',\n",
    "    padding=False,\n",
    "    final_nonlin=True,\n",
    "    momentum=0.7\n",
    ")\n",
    "\n",
    "\n",
    "shifter_dict=None\n",
    "\n",
    "\n",
    "readout_dict = dict(\n",
    "    bias=True,\n",
    "    init_mu_range=0.2,\n",
    "    init_sigma=1.0,\n",
    "    gamma_readout=0.0,\n",
    "    gauss_type='full',\n",
    "#     grid_mean_predictor=None,\n",
    "    grid_mean_predictor={\n",
    "        'type': 'cortex',\n",
    "        'input_dimensions': 2,\n",
    "        'hidden_layers': 1,\n",
    "        'hidden_features': 30,\n",
    "        'final_tanh': True\n",
    "    },\n",
    "    share_features=False,\n",
    "    share_grid=False,\n",
    "    shared_match_ids=None,\n",
    "    gamma_grid_dispersion=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6413f24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/user/turishcheva/experanto_video_dev/experanto/experanto/interpolators.py:291: UserWarning: Image size changes aspect ratio.\n",
      "  warnings.warn(\"Image size changes aspect ratio.\")\n",
      "/srv/user/turishcheva/sensorium_replicate/neuralpredictors/neuralpredictors/layers/cores/base.py:82: UserWarning: The batch_norm is applied to all layers\n",
      "  warnings.warn(f\"The {attr} is applied to all layers\", UserWarning)\n",
      "/srv/user/turishcheva/sensorium_replicate/neuralpredictors/neuralpredictors/layers/cores/base.py:82: UserWarning: The bias is applied to all layers\n",
      "  warnings.warn(f\"The {attr} is applied to all layers\", UserWarning)\n",
      "/srv/user/turishcheva/sensorium_replicate/neuralpredictors/neuralpredictors/layers/cores/base.py:82: UserWarning: The batch_norm_scale is applied to all layers\n",
      "  warnings.warn(f\"The {attr} is applied to all layers\", UserWarning)\n",
      "/srv/user/turishcheva/sensorium_replicate/neuralpredictors/neuralpredictors/layers/readouts/base.py:74: UserWarning: Use of 'gamma_readout' is deprecated. Use 'feature_reg_weight' instead. If 'feature_reg_weight' is defined, 'gamma_readout' is ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "factorised_3d_model = make_video_model(\n",
    "    data_loaders,\n",
    "    seed,\n",
    "    core_dict=factorised_3D_core_dict,\n",
    "    core_type='3D_factorised',\n",
    "    readout_dict=readout_dict.copy(),\n",
    "    readout_type='gaussian',               \n",
    "    use_gru=False,\n",
    "    gru_dict=None,\n",
    "    use_shifter=False,\n",
    "    shifter_dict=shifter_dict,\n",
    "    shifter_type='MLP',\n",
    "    deeplake_ds=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5d280e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VideoFiringRateEncoder(\n",
       "  (core): Factorized3dCore(\n",
       "    (_input_weight_regularizer): LaplaceL2norm(\n",
       "      (laplace): Laplace()\n",
       "    )\n",
       "    (temporal_regularizer): DepthLaplaceL21d(\n",
       "      (laplace): Laplace1d()\n",
       "    )\n",
       "    (features): Sequential(\n",
       "      (layer0): Sequential(\n",
       "        (conv_spatial): Conv3d(1, 32, kernel_size=(1, 11, 11), stride=(1, 1, 1))\n",
       "        (conv_temporal): Conv3d(32, 32, kernel_size=(11, 1, 1), stride=(1, 1, 1))\n",
       "        (norm): BatchNorm3d(32, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True)\n",
       "        (nonlin): ELU(alpha=1.0)\n",
       "      )\n",
       "      (layer1): Sequential(\n",
       "        (conv_spatial_1): Conv3d(32, 64, kernel_size=(1, 5, 5), stride=(1, 1, 1))\n",
       "        (conv_temporal_1): Conv3d(64, 64, kernel_size=(5, 1, 1), stride=(1, 1, 1))\n",
       "        (norm): BatchNorm3d(64, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True)\n",
       "        (nonlin): ELU(alpha=1.0)\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (conv_spatial_2): Conv3d(64, 128, kernel_size=(1, 5, 5), stride=(1, 1, 1))\n",
       "        (conv_temporal_2): Conv3d(128, 128, kernel_size=(5, 1, 1), stride=(1, 1, 1))\n",
       "        (norm): BatchNorm3d(128, eps=1e-05, momentum=0.7, affine=True, track_running_stats=True)\n",
       "        (nonlin): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "  ) [Factorized3dCore regularizers: gamma_input_spatial = 10|gamma_input_temporal = 0.01]\n",
       "  \n",
       "  (readout): MultipleFullGaussian2d(\n",
       "    (dynamic29712-5-9-Video-full): full FullGaussian2d (128 x 126 x 238 -> 7939) with bias, with predicted grid  -> Sequential(\n",
       "      (0): Linear(in_features=2, out_features=30, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "      (2): Linear(in_features=30, out_features=2, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    \n",
       "  )\n",
       "  (nonlinearity_fn): ELU(alpha=1.0)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorised_3d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03dd5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:6'\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7dd295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_fn = \"sensorium.training.video_training_loop.standard_trainer\"\n",
    "\n",
    "trainer_config = {\n",
    "    'dataloaders' : data_loaders,\n",
    "    'seed' : 111,\n",
    "    'use_wandb' : False,\n",
    "    'verbose': True,\n",
    "    'lr_decay_steps': 4,\n",
    "    'lr_init': 0.005,\n",
    "    'device' : device,\n",
    "    'detach_core' : False,\n",
    "    \n",
    "    # todo - put this to True if you are using deeplake\n",
    "    # first connections to deeplake may take up for 10 mins\n",
    "    'deeplake_ds' : False,\n",
    "    'checkpoint_save_path': './loc2/',\n",
    "    'max_iter': 3, # mock 5 epochs\n",
    "                 }\n",
    "\n",
    "trainer = get_trainer(trainer_fn=trainer_fn, \n",
    "                 trainer_config=trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ed2d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optim_step_count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [01:33<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 89, Train loss -1822454.4489400627, Validation loss -863227.4654294999\n",
      "EPOCH=1  validation_correlation=0.0006684388249446166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [01:34<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Batch 89, Train loss -4655154.800254173, Validation loss -2005556.0251530614\n",
      "EPOCH=2  validation_correlation=0.0008920188441888261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 90/90 [01:34<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Batch 89, Train loss -6796529.30666938, Validation loss -2858816.148818335\n",
      "EPOCH=3  validation_correlation=0.01820534550458816\n"
     ]
    }
   ],
   "source": [
    "validation_score, trainer_output, state_dict = trainer(factorised_3d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1233085b",
   "metadata": {},
   "source": [
    "## [Optional] Script to match tiers for new five sensorium mice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e47de",
   "metadata": {},
   "source": [
    "This works only for [these](https://gin.g-node.org/pollytur/sensorium_2023_dataset) five later released mice.  \n",
    "For [these](https://gin.g-node.org/pollytur/sensorium_2023_data/src/798ba8ad041d8f0f0ce879af396d52c7238c2730) the `trial_idx.npy` file was not released, I am working on this matching and will update it when available\n",
    "\n",
    "Current dataloader will not be able to handle the natural images partition of sensorium, but this was an OOD partition (live and final tests), so this should be fine so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eea32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085171b6",
   "metadata": {},
   "source": [
    "### Sessions without images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aae948",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_old = ...\n",
    "path_to_new = ...\n",
    "path_to_save_matching = ...\n",
    "for m in ['dynamic29515-10-12-Video-full', 'dynamic29712-5-9-Video-full']:\n",
    "    matching = {}\n",
    "    yaml_pre_path = f'{path_to_new}{m}/screen/meta/'\n",
    "    tiers_prev = np.load(f'{path_to_old}{m.replace(\"full\", \"\")}9b4f6a1a067fe51e15306b9628efea20/trials/tiers.npy')\n",
    "    trial_idx_prev = np.asarray([int(i) for i in np.load(f'{path_to_old}{m.replace(\"full\", \"\")}9b4f6a1a067fe51e15306b9628efea20/trials/trial_idx.npy')])\n",
    "    \n",
    "    for file in tqdm(os.listdir(yaml_pre_path)):\n",
    "        with open(f'{yaml_pre_path}{file}', 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        if data['modality'] != 'blank':\n",
    "            if len(np.where(trial_idx_prev ==data['trial_idx'])[0]) ==0:\n",
    "                matching[data['trial_idx']] = 'none'\n",
    "            else:\n",
    "                matching[data['trial_idx']] = tiers_prev[np.where(trial_idx_prev == data['trial_idx'])[0]][0]\n",
    "    print(m)\n",
    "    print(Counter(matching.values()))\n",
    "    print(Counter(tiers_prev))\n",
    "    print('\\n\\n')\n",
    "    \n",
    "    with open(f'{path_to_save_matching}/{m.replace(\"-Video-full\", \"_match\")}.pkl', 'wb') as f:\n",
    "        pickle.dump(matching, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6743ae",
   "metadata": {},
   "source": [
    "### Sessions with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2590803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in ['dynamic29623-4-9-Video-full', 'dynamic29647-19-8-Video-full', 'dynamic29755-2-8-Video-full']:\n",
    "    matching = {}\n",
    "    yaml_pre_path = f'{path_to_new}{m}/screen/meta/'\n",
    "    tiers_prev = np.load(f'{path_to_old}{m.replace(\"full\", \"\")}9b4f6a1a067fe51e15306b9628efea20/trials/tiers.npy')\n",
    "    trial_idx_prev_ = np.load(f'{path_to_old}{m.replace(\"full\", \"\")}9b4f6a1a067fe51e15306b9628efea20/trials/trial_idx.npy')\n",
    "\n",
    "\n",
    "    trial_idx_prev = []\n",
    "    images = []\n",
    "    imaged_idx = []\n",
    "    not_found = []\n",
    "    for idx, i in enumerate(trial_idx_prev_):\n",
    "        if len(i.split('--')) == 1:\n",
    "            trial_idx_prev.append(int(i))\n",
    "        else:\n",
    "            trial_idx_prev.append(-1)\n",
    "            images.append([int(j) for j in i.split('--')])\n",
    "            imaged_idx.append(idx)\n",
    "    trial_idx_prev = np.asarray(trial_idx_prev)\n",
    "    \n",
    "    for file in tqdm(os.listdir(yaml_pre_path)):\n",
    "        with open(f'{yaml_pre_path}{file}', 'r') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        if data['modality'] != 'blank':\n",
    "            if len(np.where(trial_idx_prev ==data['trial_idx'])[0]) ==0:\n",
    "                found = False\n",
    "                for num, lst in enumerate(images):\n",
    "                    if data['trial_idx'] in lst:\n",
    "                        matching[data['trial_idx']] = tiers_prev[imaged_idx[num]]\n",
    "                        found = True\n",
    "                # assert found, f\"id not found! {m} {file}\"\n",
    "                if not found:\n",
    "                    not_found.append(file)\n",
    "                    matching[data['trial_idx']] = 'none'\n",
    "                    \n",
    "            else:\n",
    "                matching[data['trial_idx']] = tiers_prev[np.where(trial_idx_prev == data['trial_idx'])[0]][0]\n",
    "    print(m)\n",
    "    print(f'not found {len(not_found)}, len(matching)={len(matching)}, len(tiers_prev) = {len(tiers_prev)}')\n",
    "    print(Counter(matching.values()))\n",
    "    print(Counter(tiers_prev))\n",
    "    \n",
    "    print('\\n\\n')\n",
    "    with open(f'{path_to_save_matching}{m.replace(\"-Video-full\", \"_match\")}.pkl', 'wb') as f:\n",
    "        pickle.dump(matching, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
